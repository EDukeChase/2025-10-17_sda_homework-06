---
title: "Homework-06: Regional Count Data Homework (Spatial Autocorrelation)"
author: "E. Duke Chase"
date: today
---

```{r}
#| label: setup
#| include: false

library(here)
source(here::here("R", "setup.R"))

# Set key directory paths
data_dir <- here::here("data")
output_dir <- here::here("output")
```

The `lip_sf` is an `sf` data frame with 53 rows representing counties and 5 variables. The data frame contains 53 county-level observations for lip cancer among males in Scotland between 1975-1980. The variables are:

-   `name`: county name
-   `cancer`: number of Lip cancer cases in the county (Cressie 1993)
-   `population`: county population size (Cressie 1993)
-   `expected`: expected number of lip cancer cases (Lawson 1999)
-   `geometry`: geometric representation of counties in Scotland.

Source Kemp I., Boyle P., Smans M. and Muir C. (1985) Atlas of cancer in Scotland, 1975-1980, incidence and epidemiologic perspective. *International Agency for Research on Cancer*. 72

Cressie, N. A. C. (1993). Statistics for Spatial Data. New York: John Wiley & Sons, p. 537 Table 7.2.

Lawson, A., Biggeri, A., Böhning, D., Lesaffre, E., Viel, J. F., & Bertollini, R. (Eds.). (1999). Disease Mapping and Risk Assessment for Public Health. New York: Wiley, pp. 68-69, Table 5.1.

We run the following command to load `lip_sf` (assuming the `.rda` is in your search path).

```{r}
#| label: load-data

load(here("data", "lip_sf.rda"))
```

We run the following commands to geometrically obtain centroids for each county and create a neighborhood object for the data.

```{r}
#| label: obtain-centroids

coords <- st_coordinates(st_centroid(st_geometry(lip_sf)))
lip_nb <- poly2nb(lip_sf, queen=TRUE)
```

# Problem 1

Plot the neighborhood connections stored in `lip_nb`. What do you observe?

**Solution**

```{r}
#| label: p_1

plot(st_geometry(lip_sf))
plot(lip_nb, coords, add = TRUE, col = "blue", pch = 19, cex = 0.6)
```


# Problem 2

Use the Moran’s I statistic to test whether there is evidence of positive spatial autocorrelation for the `cancer` variable under the constant risk hypothesis. Use a row standardized weights matrix for the `lip_nb` neighbor relationship. Use the `expected` counts stored in `lip_sf` for the expected counts. Provide the observed test statistic, the p-value, and interpret your results in the context of the problem.

**Solution**

```{r}
#| label: p_2

lw_w <- nb2listw(lip_nb, style = "W")

N <- length(lip_sf$cancer)
y <- lip_sf$cancer
n <- lip_sf$population
rni <- lip_sf$expected

nsim <- 499
t0_w <- moran(y, listw = lw_w, n = N, S0 = Szero(lw_w))$I
tsim_w <- numeric(nsim)

for (i in 1:nsim){
  tsim_w[i] <- moran(rpois(N, rni), listw = lw_w, n = N, S0 = Szero(lw_w))$I
}

pval_2 <- (sum(tsim_w >= t0_w) + 1) / (nsim + 1)
```

::: {.answer-box}
  The observed test statistic is $t_{obs} =$ `r round(t0_w, 4)`, and the p-value is `r pval_2`.
:::



# Problem 3

Use the constant risk version of Moran’s I (Walter 1992) to test whether there is evidence of positive spatial autocorrelation for the `cancer` variable under the CRH. Use a row binary weights matrix for the `lip_nb` neighbor relationship. Use the `expected` counts stored in `lip_sf` for the expected counts. Interpret your results in the context of the problem.

**Solution**

```{r}
#| label: p_3

lw_b <- nb2listw(lip_nb, style = "B")

nsim <- 499
t0_b <- moran(y, listw = lw_b, n = N, S0 = Szero(lw_b))$I
tsim_b <- numeric(nsim)

for (i in 1:nsim){
  tsim_b[i] <- moran(rpois(N, rni), listw = lw_b, n = N, S0 = Szero(lw_b))$I
}

pval_3 <- (sum(tsim_b >= t0_b) + 1) / (nsim + 1)
```

::: {.answer-box}
  The observed test statistic is $t_{obs} =$ `r round(t0_b, 4)`, and the p-value is `r pval_3`.
:::

# Problem 4

The intercentroid distances for the North Carolina <span style="color:blue;">(Scotland?)</span> data are between 4866.044 and 396,350.916. In the context of Tango’s recommended weights matrix, a very weak spatial correlation $\kappa=5000$ and a very strong spatial correlation has $\kappa=200000$. Perform Monte Carlo tests using using Tango's index with Tango's recommended weights with both $\kappa=5000$ and $\kappa=200000$ for the `cancer` variable with 499 simulated data sets. Interpret your results in the context of the problem.

**Solution**

```{r}
#| label: p_4

# Exponential decay weight matrix w/ two kappa values
w_5 <- dweights(coords, kappa = 5000)
w_200 <- dweights(coords, kappa = 200000)

# Calculate Tango's statistic
t_5 <- tango.test(cases = y, pop = n, w_5)
t_200 <- tango.test(cases = y, pop = n, w_200)

# Compare monte carlo p-value to chi-square approximation p-value
(tango_mc5 <- tango.test(cases = y, pop = n, w_5, nsim = 499))
(tango_mc200 <- tango.test(cases = y, pop = n, w_200, nsim = 499))
```


# Problem 5

Compare the goodness-of-fit and spatial autocorrelation components of Tango’s statistic for the observed and simulated data in a plot. (Do this for both values of $\kappa$). Are the patterns similar for the weak versus strong spatial autocorrelation? Or does the value of $\kappa$ dramatically impact the relative importance of the goodness-of-fit and spatial autocorrelation components?

**Solution**

```{r}
#| label: p_5 
#| layout-ncol: 2
#| layout-align: center
#| fig-asp: 1
#| fig-column: page

plot(tango_mc5,
     main = expression(paste(kappa, " = 5,000")),
     xlab = "spatial autocorrelation",
     ylab = "goodness-of-fit",
     cex.main = 2.5,
     cex.lab = 2,
     cex.axis = 1.3,
     obs.list = list(pch = 19, col = "purple"),
     sim.list = list(pch = 20, col = "darkgray"))

plot(tango_mc200,
     main = expression(paste(kappa, " = 200,000")),
     xlab = "spatial autocorrelation",
     ylab = "goodness-of-fit",
     cex.main = 2.5,
     cex.lab = 2,
     cex.axis = 1.3,
     obs.list = list(pch = 19, col = "purple"),
     sim.list = list(pch = 20, col = "darkgray"))
```


# Problem 6

In this problem you are going to implement a portion of the spatial scan method. You can only use functions/packages loaded with by default by R (`stats`, `graphics`, `grDevices`, `utils`, `datasets`, `methods`, `base`). If you don't have to load a package to access the functionality, then you should be okay.

Suppose you have regional count data with the following characteristics:

```{r}
#| label: p_6-setup
#| include: false

region_id <- seq_len(4)
x <- c(1, 3, 2, 0)
y <- c(2, 1, 1.5, 2)
cases <- c(1, 3, 3, 4)
pop <- c(2, 4, 6, 4)
dtf <- data.frame(region_id, x, y, cases, population = pop)
```

```{r}
#| echo: false
knitr::kable(dtf)
```

(`x`, `y`) define the centroid of each region.

Calculate the Poisson spatial scan statistic under the CRH assuming the constraint that no more than half the total population can be in a potential cluster/window.

Break up your solution into parts:

## (a)

Compute the inter-centroid distance matrix between all centroids.

Return the sample mean of this matrix.

**Solution**

```{r}
#| label: p_6-a

ss_coords <- as.matrix(dtf[, c("x", "y")])
d_mat <- dist(ss_coords)
```

::: {.answer-box}
  The sample mean of the inter-centroid distance matrix is `r round(mean(d_mat), 3)`.
:::


## (b)

Using the distance matrix above, determine all possible windows (in terms of the region ids each window includes) in terms of nearest neighbors (the largest would have 3 non-inclusive neighbors). Print the complete list of windows.

**Solution**

```{r}
#| label: p_6-b

dist_mat <- as.matrix(d_mat)
n_reg <- nrow(dtf)

# Create empty list to store all windows
window_list <- list()

for (i in 1:n_reg) {
  # Get dist from region i
  dist_from_i <- dist_mat[i, ]
  
  # Get indices of regions in order of distance from region i
  ordered_indices <- order(dist_from_i)
  
  # Loop through and create all windows starting with region i
  for (j in 1:n_reg) {
    window_list <- append(window_list, list(ordered_indices[1:j]))
  }
}

# Create a data frame to reference for later problems
sss_df <- data.frame(
  window_ids = I(window_list)
)

sss_df$window <- unlist(lapply(sss_df$window_ids, function(w) {
  paste(w, collapse = ", ")
}))

knitr::kable(
  sss_df["window"], 
  caption = "All Nearest-Neighbor Windows",
  col.names = "Window (Regions)"
)
```


## (c)

Determine the population size of each window to identify which windows have less than 50% of the total population. Print the population of each window

**Solution**

```{r}
#| label: p_6-c

# Calculate total population
tot_pop <- sum(dtf$population)

# Add pop in each window to data frame
sss_df$win_pop <- unlist(lapply(sss_df$window_ids, function(w) {
  sum(dtf$population[w])
}))

# Add a formatted population string column
sss_df$win_pop_str <- sprintf("%d (%.1f%%)",
                              sss_df$win_pop,
                              (sss_df$win_pop / tot_pop) * 100
                              )

# Print table with pop data
knitr::kable(
  sss_df[, c("window", "win_pop_str")], 
  caption = "Population of All Windows",
  col.names = c("Window (Regions)", "Window Population (% Total)")
)
```

## (d)

Only retain the windows that satisfy the population constraint. Print the list of retained windows.

**Solution**

```{r}
#| label: p_6-d

# Filter out windows that surpass the population threshold
pop_thresh = 0.5 * tot_pop
valid_windows_df <- sss_df[sss_df$win_pop <= pop_thresh, ]

# Print table only containing valid windows
knitr::kable(
  valid_windows_df[, c("window", "win_pop_str")],
  caption = "Valid Windows With 50% Population Constraint",
  col.names = c("Valid Windows (Regions)", "Window Pop (% Total)")
)
```

## (e)

For each remaining window, compute $Y_{in}$, $Y_{out}$, $E_{in}$, $E_{out}$. Print a data frame/matrix with the columns $Y_{in}$, $Y_{out}$, $E_{in}$, $E_{out}$.

**Solution**

```{r}
#| label: p_6-e

# Get total number of cases
tot_cases <- sum(dtf$cases)

# Add the four new columns
valid_windows_df$y_in <- unlist(lapply(valid_windows_df$window_ids, function(w) {
  sum(dtf$cases[w])
}))
valid_windows_df$y_out <- tot_cases - valid_windows_df$y_in
valid_windows_df$e_in <- tot_cases * (valid_windows_df$win_pop / tot_pop)
valid_windows_df$e_out <- tot_cases - valid_windows_df$e_in

# Print the table with this new data
knitr::kable(
  valid_windows_df[, c("window", "y_in", "y_out", "e_in", "e_out")],
  caption = "Statistics for Valid Windows",
  col.names = c("window", "Y<sub>in</sub>", "Y<sub>out</sub>", "E<sub>in</sub>", "E<sub>out</sub>"),
  digits = c(NA, 0, 0, 2, 2)
)
```

## (f)

Compute the statistic $\left(\frac{Y_{in}}{E_{in}}\right)^{Y_{in}} \left(\frac{Y_{out}}{E_{out}}\right)^{Y_{out}} I\left(\frac{Y_{in}}{E_{in}} \geq \frac{Y_{out}}{E_{out}}\right)$ for each remaining window.

**Solution**

```{r}
#| label: p_6-f

# Compute the ratios
ratio_in <- valid_windows_df$y_in / valid_windows_df$e_in
ratio_out <- valid_windows_df$y_out / valid_windows_df$e_out

# Compute the indicator function
indicator <- (ratio_in >= ratio_out)

# Calculate the exponent parts
ratio_in_exp <- ratio_in ^ valid_windows_df$y_in
ratio_out_exp <- ratio_out ^ valid_windows_df$y_out

# Calculate the test statistics
valid_windows_df$test_stat <- ratio_in_exp * ratio_out_exp * indicator

# Print the table
knitr::kable(
  valid_windows_df[, c("window", "test_stat")],
  caption = "Test Stat for Valid Windows",
  col.names = c("Window", "Test Statistic"),
  digits = c(NA, 4)
)
```