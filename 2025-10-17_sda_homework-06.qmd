---
title: "Homework-06: Regional Count Data Homework (Spatial Autocorrelation)"
author: "E. Duke Chase"
date: today
---

```{r}
#| label: setup
#| include: false

library(here)
source(here::here("R", "setup.R"))

# Set key directory paths
data_dir <- here::here("data")
output_dir <- here::here("output")
```

The `lip_sf` is an `sf` data frame with 53 rows representing counties and 5 variables. The data frame contains 53 county-level observations for lip cancer among males in Scotland between 1975-1980. The variables are:

-   `name`: county name
-   `cancer`: number of Lip cancer cases in the county (Cressie 1993)
-   `population`: county population size (Cressie 1993)
-   `expected`: expected number of lip cancer cases (Lawson 1999)
-   `geometry`: geometric representation of counties in Scotland.

Source Kemp I., Boyle P., Smans M. and Muir C. (1985) Atlas of cancer in Scotland, 1975-1980, incidence and epidemiologic perspective. *International Agency for Research on Cancer*. 72

Cressie, N. A. C. (1993). Statistics for Spatial Data. New York: John Wiley & Sons, p. 537 Table 7.2.

Lawson, A., Biggeri, A., Böhning, D., Lesaffre, E., Viel, J. F., & Bertollini, R. (Eds.). (1999). Disease Mapping and Risk Assessment for Public Health. New York: Wiley, pp. 68-69, Table 5.1.

We run the following command to load `lip_sf` (assuming the `.rda` is in your search path).

```{r}
#| label: load-data

load(here("data", "lip_sf.rda"))
```

We run the following commands to geometrically obtain centroids for each county and create a neighborhood object for the data.

```{r}
#| label: obtain-centroids

coords <- st_coordinates(st_centroid(st_geometry(lip_sf)))
lip_nb <- poly2nb(lip_sf, queen=TRUE)
```

# Problem 1

Plot the neighborhood connections stored in `lip_nb`. What do you observe?

**Solution**

```{r}
#| label: p_1
#| fig-width: 8
#| fig-asp: 1
#| fig-cap: "Connections of Scottish Counties"

plot(st_geometry(lip_sf))
plot(lip_nb, coords, add = TRUE, col = "blue", pch = 19, cex = 0.6)
```

::: {.answer-box}
  This map of Scotland is basically just showing the number of neighboring counties for each county. Smaller southern counties tend to have a greater number of neighbors because they're packed tightly, whereas for northern counties there tend to be fewer neighbors due to the constraints of size and the surrounding ocean limiting the possible number of neighbors for each county.
:::


# Problem 2

Use the Moran’s I statistic to test whether there is evidence of positive spatial autocorrelation for the `cancer` variable under the constant risk hypothesis. Use a row standardized weights matrix for the `lip_nb` neighbor relationship. Use the `expected` counts stored in `lip_sf` for the expected counts. Provide the observed test statistic, the p-value, and interpret your results in the context of the problem.

**Solution**

```{r}
#| label: p_2

lw_w <- nb2listw(lip_nb, style = "W")

N <- length(lip_sf$cancer)
y <- lip_sf$cancer
n <- lip_sf$population
rni <- lip_sf$expected

nsim <- 499
t0_w <- moran(y, listw = lw_w, n = N, S0 = Szero(lw_w))$I
tsim_w <- numeric(nsim)

for (i in 1:nsim){
  tsim_w[i] <- moran(rpois(N, rni), listw = lw_w, n = N, S0 = Szero(lw_w))$I
}

pval_2 <- (sum(tsim_w >= t0_w) + 1) / (nsim + 1)
```

::: {.answer-box}
  The observed test statistic is $t_{obs} =$ `r round(t0_w, 4)`, and the p-value is `r pval_2`.
  
  The positive $t_{\text{obs}}$ value and significant p-value indicate that there is clustering of lip cancer cases in Scotland compared to what would be expected based on CRH, i.e., there is significant evidence that the cases aren't just randomly distributed, but that there is strong spatial autocorrelation with counties that have higher than expected lip cancer rates tending to be bunched together, although this test doesn't indicate where.
:::



# Problem 3

Use the constant risk version of Moran’s I (Walter 1992) to test whether there is evidence of positive spatial autocorrelation for the `cancer` variable under the CRH. Use a row binary weights matrix for the `lip_nb` neighbor relationship. Use the `expected` counts stored in `lip_sf` for the expected counts. Interpret your results in the context of the problem.

**Solution**

```{r}
#| label: p_3

lw_b <- nb2listw(lip_nb, style = "B")

nsim <- 499
t0_b <- moran(y, listw = lw_b, n = N, S0 = Szero(lw_b))$I
tsim_b <- numeric(nsim)

for (i in 1:nsim){
  tsim_b[i] <- moran(rpois(N, rni), listw = lw_b, n = N, S0 = Szero(lw_b))$I
}

pval_3 <- (sum(tsim_b >= t0_b) + 1) / (nsim + 1)
```

::: {.answer-box}
  The observed test statistic is $t_{obs} =$ `r round(t0_b, 4)`, and the p-value is `r pval_3`.
  
  As with problem 2, the positive $t_{\text{obs}}$ value and very significant p-value indicate the present of spatial autocorrelation where Scottish counties that have more lip cancer cases than expected under CRH tend to be close together. Using the binary row weights matrix instead of the row standardized weights matrix as in problem 2 did result in $t_{\text{obs}}$ being notably less positive than in problem 2. The binary row weights matrix weights counties with more neighbors more heavily than counties with fewer neighbors (unlike the row standardized weights matrix), so this would maybe indicate that the more southern Scottish counties that tend to have more neighbors might also have lower rates of lip cancer (which is consistent with past work we've done on this data set).
:::

# Problem 4

The intercentroid distances for the North Carolina <span style="color:blue;">(Scotland?)</span> data are between 4866.044 and 396,350.916. In the context of Tango’s recommended weights matrix, a very weak spatial correlation $\kappa=5000$ and a very strong spatial correlation has $\kappa=200000$. Perform Monte Carlo tests using using Tango's index with Tango's recommended weights with both $\kappa=5000$ and $\kappa=200000$ for the `cancer` variable with 499 simulated data sets. Interpret your results in the context of the problem.

**Solution**

```{r}
#| label: p_4

# Exponential decay weight matrix w/ two kappa values
w_5 <- dweights(coords, kappa = 5000)
w_200 <- dweights(coords, kappa = 200000)

# Calculate Tango's statistic
t_5 <- tango.test(cases = y, pop = n, w_5)
t_200 <- tango.test(cases = y, pop = n, w_200)

# Compare monte carlo p-value to chi-square approximation p-value
tango_mc5 <- tango.test(cases = y, pop = n, w_5, nsim = 499)
tango_mc200 <- tango.test(cases = y, pop = n, w_200, nsim = 499)

# Create data frame of results
results_df <- data.frame(
  Kappa = c("5,000 (Weak)", "200,000 (Strong)"),
  Index = c(tango_mc5$tstat, tango_mc200$tstat),
  GOF = c(tango_mc5$gof, tango_mc200$gof),
  SA = c(tango_mc5$sa, tango_mc200$sa),
  p_value = c(tango_mc5$pvalue.sim, tango_mc200$pvalue.sim)
)

# Print results
knitr::kable(
  results_df,
  caption = "Tango's Index Results for Weak vs. Strong Spatial Correlation",
  col.names = c("Kappa (k)", "Tango's Index", "Goodness-of-Fit", "Spatial Autocorrelation", "MC p-value"),
  digits = c(NA, 3, 3, 4, 3) # Specify rounding for each column
)
```

::: {.answer-box}
  Both tests had significant p-values, so there is evidence that the spatial pattern of lip cancer cases in Scotland exhibits significant clustering and is not consistent with CRH. The $\kappa = 5,000$ parameter shows that there is significant clustering of lip cancer on small scales, only looking at very close neighbors, and the $\kappa = 200,000$ parameter being significant shows that there is significant clustering of lip cancer on large scales too. The goodness-of-fit is identical in both cases, which it should be, since changes in $\kappa$ shouldn't affect that. The spatial autocorrelation is very different between the tests, with it being more than 20 times higher for the larger $\kappa$ value, which indicates that the pattern is more likely to be a broad one than super localized.
:::


# Problem 5

Compare the goodness-of-fit and spatial autocorrelation components of Tango’s statistic for the observed and simulated data in a plot. (Do this for both values of $\kappa$). Are the patterns similar for the weak versus strong spatial autocorrelation? Or does the value of $\kappa$ dramatically impact the relative importance of the goodness-of-fit and spatial autocorrelation components?

**Solution**

```{r}
#| label: p_5 
#| layout-ncol: 2
#| layout-align: center
#| fig-asp: 1
#| fig-column: page

plot(tango_mc5,
     main = expression(paste(kappa, " = 5,000")),
     xlab = "spatial autocorrelation",
     ylab = "goodness-of-fit",
     cex.main = 2.5,
     cex.lab = 2,
     cex.axis = 1.3,
     obs.list = list(pch = 19, col = "purple"),
     sim.list = list(pch = 20, col = "darkgray"))

plot(tango_mc200,
     main = expression(paste(kappa, " = 200,000")),
     xlab = "spatial autocorrelation",
     ylab = "goodness-of-fit",
     cex.main = 2.5,
     cex.lab = 2,
     cex.axis = 1.3,
     obs.list = list(pch = 19, col = "purple"),
     sim.list = list(pch = 20, col = "darkgray"))
```

::: {.answer-box}
  As noted before, the goodness-of-fit is approximately the same for both $\kappa$ values, but the spatial autocorrelation is very different depending on the value of $\kappa$. For $\kappa = 5,000$, the observed data, while extreme compared to the CRH compliant simulated data, is much closer to the simulated data than it is with $\kappa = 200,000$ when looking at spatial autocorrelation. This indicates that while it is extreme, and indicative of clustering, with the very weak spatial correlation, goodness-of-fit is a much stronger contributor to what is differentiation the observed data from the simulated data than it is for very strong spatial correlation. This points to the clustering of lip cancer cases in Scotland being a more regional phenomenon.
:::


# Problem 6

In this problem you are going to implement a portion of the spatial scan method. You can only use functions/packages loaded with by default by R (`stats`, `graphics`, `grDevices`, `utils`, `datasets`, `methods`, `base`). If you don't have to load a package to access the functionality, then you should be okay.

Suppose you have regional count data with the following characteristics:

```{r}
#| label: p_6-setup
#| include: false

region_id <- seq_len(4)
x <- c(1, 3, 2, 0)
y <- c(2, 1, 1.5, 2)
cases <- c(1, 3, 3, 4)
pop <- c(2, 4, 6, 4)
dtf <- data.frame(region_id, x, y, cases, population = pop)
```

```{r}
#| echo: false
knitr::kable(dtf)
```

(`x`, `y`) define the centroid of each region.

Calculate the Poisson spatial scan statistic under the CRH assuming the constraint that no more than half the total population can be in a potential cluster/window.

Break up your solution into parts:

## (a)

Compute the inter-centroid distance matrix between all centroids.

Return the sample mean of this matrix.

**Solution**

```{r}
#| label: p_6-a

ss_coords <- as.matrix(dtf[, c("x", "y")])
d_mat <- dist(ss_coords)
```

::: {.answer-box}
  The sample mean of the inter-centroid distance matrix is `r round(mean(d_mat), 3)`.
:::


## (b)

Using the distance matrix above, determine all possible windows (in terms of the region ids each window includes) in terms of nearest neighbors (the largest would have 3 non-inclusive neighbors). Print the complete list of windows.

**Solution**

```{r}
#| label: p_6-b

dist_mat <- as.matrix(d_mat)
n_reg <- nrow(dtf)

# Create empty list to store all windows
window_list <- list()

for (i in 1:n_reg) {
  # Get dist from region i
  dist_from_i <- dist_mat[i, ]
  
  # Get indices of regions in order of distance from region i
  ordered_indices <- order(dist_from_i)
  
  # Loop through and create all windows starting with region i
  for (j in 1:n_reg) {
    window_list <- append(window_list, list(ordered_indices[1:j]))
  }
}

# Create a data frame to reference for later problems
sss_df <- data.frame(
  window_ids = I(window_list)
)

sss_df$window <- unlist(lapply(sss_df$window_ids, function(w) {
  paste(w, collapse = ", ")
}))

knitr::kable(
  sss_df["window"], 
  caption = "All Nearest-Neighbor Windows",
  col.names = "Window (Regions)"
)
```


## (c)

Determine the population size of each window to identify which windows have less than 50% of the total population. Print the population of each window

**Solution**

```{r}
#| label: p_6-c

# Calculate total population
tot_pop <- sum(dtf$population)

# Add pop in each window to data frame
sss_df$win_pop <- unlist(lapply(sss_df$window_ids, function(w) {
  sum(dtf$population[w])
}))

# Add a formatted population string column
sss_df$win_pop_str <- sprintf("%d (%.1f%%)",
                              sss_df$win_pop,
                              (sss_df$win_pop / tot_pop) * 100
                              )

# Print table with pop data
knitr::kable(
  sss_df[, c("window", "win_pop_str")], 
  caption = "Population of All Windows",
  col.names = c("Window (Regions)", "Window Population (% Total)")
)
```

## (d)

Only retain the windows that satisfy the population constraint. Print the list of retained windows.

**Solution**

```{r}
#| label: p_6-d

# Filter out windows that surpass the population threshold
pop_thresh = 0.5 * tot_pop
valid_windows_df <- sss_df[sss_df$win_pop <= pop_thresh, ]

# Print table only containing valid windows
knitr::kable(
  valid_windows_df[, c("window", "win_pop_str")],
  caption = "Valid Windows With 50% Population Constraint",
  col.names = c("Valid Windows (Regions)", "Window Pop (% Total)")
)
```

## (e)

For each remaining window, compute $Y_{in}$, $Y_{out}$, $E_{in}$, $E_{out}$. Print a data frame/matrix with the columns $Y_{in}$, $Y_{out}$, $E_{in}$, $E_{out}$.

**Solution**

```{r}
#| label: p_6-e

# Get total number of cases
tot_cases <- sum(dtf$cases)

# Add the four new columns
valid_windows_df$y_in <- unlist(lapply(valid_windows_df$window_ids, function(w) {
  sum(dtf$cases[w])
}))
valid_windows_df$y_out <- tot_cases - valid_windows_df$y_in
valid_windows_df$e_in <- tot_cases * (valid_windows_df$win_pop / tot_pop)
valid_windows_df$e_out <- tot_cases - valid_windows_df$e_in

# Print the table with this new data
knitr::kable(
  valid_windows_df[, c("window", "y_in", "y_out", "e_in", "e_out")],
  caption = "Statistics for Valid Windows",
  col.names = c("window", "Y<sub>in</sub>", "Y<sub>out</sub>", "E<sub>in</sub>", "E<sub>out</sub>"),
  digits = c(NA, 0, 0, 2, 2)
)
```

## (f)

Compute the statistic $\left(\frac{Y_{in}}{E_{in}}\right)^{Y_{in}} \left(\frac{Y_{out}}{E_{out}}\right)^{Y_{out}} I\left(\frac{Y_{in}}{E_{in}} \geq \frac{Y_{out}}{E_{out}}\right)$ for each remaining window.

**Solution**

```{r}
#| label: p_6-f

# Compute the ratios
ratio_in <- valid_windows_df$y_in / valid_windows_df$e_in
ratio_out <- valid_windows_df$y_out / valid_windows_df$e_out

# Compute the indicator function
indicator <- (ratio_in >= ratio_out)

# Calculate the exponent parts
ratio_in_exp <- ratio_in ^ valid_windows_df$y_in
ratio_out_exp <- ratio_out ^ valid_windows_df$y_out

# Calculate the test statistics
valid_windows_df$test_stat <- ratio_in_exp * ratio_out_exp * indicator

# Print the table
knitr::kable(
  valid_windows_df[, c("window", "test_stat")],
  caption = "Test Stat for Valid Windows",
  col.names = c("Window", "Test Statistic"),
  digits = c(NA, 4)
)
```